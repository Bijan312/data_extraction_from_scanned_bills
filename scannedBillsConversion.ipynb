{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1052793-da74-4189-afa9-edae95408386",
   "metadata": {},
   "source": [
    "# Data extraction from a company's bills\n",
    "\n",
    "The data is in Persian; thus, the characters are different from English. So that, I had to use Image processing.\n",
    "* First, the ROI calibrated to encompass the desired data.\n",
    "* Secondly, text data was detected from tables.\n",
    "* Ultimately, extracted data grasped as pandas dataFrame.\n",
    "\n",
    "In some pages, tables could not be detected right. So, I tried to extract them as text and then convert them into DataFrames.\n",
    "\n",
    "The following code is the gist of what I utilized to attain data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c53e760-b293-4053-a7de-4e29e1aa8118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'\n",
    "\n",
    "# Define the coordinates of the area you want to crop in PDF points (x0, y0, x1, y1)\n",
    "crop_box = (35, 150, 400, 250)\n",
    "\n",
    "# Step 1: Convert PDF pages to images\n",
    "pages = convert_from_path(\"some_bills.pdf\", dpi=300)\n",
    "text_data = []\n",
    "all_tables = []  # Store manually parsed tables for further analysis\n",
    "\n",
    "with pdfplumber.open(\"some_bills.pdf\") as pdf:\n",
    "    for page_num, (page_image, pdf_page) in enumerate(zip(pages, pdf.pages)):\n",
    "        # Get the dimensions of the PDF page and image for scaling\n",
    "        pdf_width, pdf_height = pdf_page.width, pdf_page.height\n",
    "        img_width, img_height = page_image.size\n",
    "        \n",
    "        # Calculate scaling factors\n",
    "        scale_x = img_width / pdf_width\n",
    "        scale_y = img_height / pdf_height\n",
    "        \n",
    "        # Scale the crop box coordinates to match the image dimensions\n",
    "        scaled_crop_box = (\n",
    "            int(crop_box[0] * scale_x),\n",
    "            int(crop_box[1] * scale_y),\n",
    "            int(crop_box[2] * scale_x),\n",
    "            int(crop_box[3] * scale_y)\n",
    "        )\n",
    "        \n",
    "        # Step 2: Crop the image to the scaled area and perform OCR\n",
    "        cropped_image = page_image.crop(scaled_crop_box)\n",
    "        text = pytesseract.image_to_string(cropped_image, lang=\"fas\", config=\"--psm 6\")\n",
    "        text_data.append(text)\n",
    "\n",
    "        # Step 3: Try to manually parse the extracted text as a table\n",
    "        if text:\n",
    "            # Split lines and attempt to format as a table\n",
    "            rows = [line.split() for line in text.splitlines() if line.strip()]  # Split by whitespace\n",
    "            if rows:\n",
    "                df = pd.DataFrame(rows)  # Convert to DataFrame for each page's table\n",
    "                all_tables.append(df)\n",
    "                print(f\"Table-like data extracted from cropped area on page {page_num + 1}:\")\n",
    "                print(df)\n",
    "\n",
    "# Print the OCR results\n",
    "print(\"Text extracted from the cropped area:\", text_data)\n",
    "\n",
    "# Combine extracted tables if any were successfully parsed\n",
    "if all_tables:\n",
    "    combined_df = pd.concat(all_tables, ignore_index=True)\n",
    "    print(\"\\nCombined table data for analysis:\")\n",
    "    print(combined_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
